1. Exempt Deployer
Internal Compliance Checklist:
[ ] Verify and Document Eligibility: Internally confirm and document that your business meets all four criteria for the small business exemption (fewer than 50 full-time employees, no use of own data for training, use for intended purpose, and system learning is not based on your data).    

[ ] Review Developer Documentation: Obtain, review, and securely store all documentation provided by the AI system's developer, including statements on purpose, limitations, and risk mitigation.    

[ ] Establish Internal Policy: Create a simple internal policy for employees on the proper and intended use of the AI system, consistent with the developer's guidelines.

[ ] Designate Responsibility: Assign a specific person or team within your organization to handle all consumer inquiries related to AI-assisted decisions.

Compliance Documentation Requirements & AI Agent Elicitation Protocol
As an Exempt Deployer, you are not required to produce formal impact assessments or a public website statement. Your primary "documentation" is a well-defined and consistently executed process for handling consumer inquiries.

Document 1: Consumer Inquiry and Redress Process

Required Information:

A clear, step-by-step process for consumers to follow if they wish to inquire about or contest a decision influenced by the AI system.

Designated contact information (e.g., email address, web form, phone number) for submitting inquiries.

An internal protocol for how your designated team will review and respond to these inquiries.

AI Agent Elicitation Questions:

"What is the exact step-by-step process a consumer should follow to ask about a decision made with the help of the AI system?"

"Please provide the specific contact information (e.g., email address 'AI-inquiry@yourcompany.com', a link to a web form) that consumers should use for these inquiries."

"Describe the internal procedure your team will follow to review a consumer's inquiry. Who is involved, and what information will they review?"

"What information are you prepared to share with a consumer who questions a decision? This will help draft a template response that leverages the documentation provided by the system's developer."

2. General AI System with Disclosure Duty
Internal Compliance Checklist:
[ ] Inventory AI Systems: Identify and create an internal list of all consumer-facing systems that use AI to interact with consumers (e.g., chatbots, virtual assistants, automated email responders).    

[ ] Conduct 'Obviousness' Assessment: For each system, conduct and internally document an assessment of whether a reasonable person would obviously know they are interacting with an AI.    

[ ] Implement Disclosure Mechanism: For any system where the AI nature is not obvious, technically implement the disclosure mechanism so that it is presented clearly and conspicuously at or before the start of the interaction.    

Compliance Documentation Requirements & AI Agent Elicitation Protocol
The only required compliance "document" for this classification is the disclosure itself, along with internal records justifying your decisions.

Document 1: AI Interaction Disclosure

Required Information:

A clear and conspicuous statement informing the consumer they are interacting with an AI system.    

This disclosure must be presented at or before the interaction begins.

Internal Record 1: 'Obviousness' Assessment Justification

Required Information:

A record for each AI system explaining the rationale for why a disclosure is or is not needed.

AI Agent Elicitation Questions:

"For each of your consumer-facing AI systems, please provide its name and primary function."

"Provide the exact text for your AI disclosure statement (e.g., 'You are interacting with an AI assistant.')."

"Describe precisely where and when this disclosure will appear to the user (e.g., 'As the first message in the chat window before the user can type,' or 'In a persistent banner at the top of the interface')."

"If you have determined that a disclosure is not needed for a particular system, provide the detailed justification. Why would a reasonable person find it obvious they are interacting with AI? If there is not obvious reason or you are choosing to add an explicit disclosure, please put N/A."

Question Notes:
If they answer anything except N/A, they don't need to answer the 2nd and 3rd questions. Make sure this is implemented in the questionairre logic. 

3. Developer of High-Risk AI System
Internal Compliance Actions
[ ] Implement 'Reasonable Care' Processes: Establish and document your internal processes for identifying, testing for, and mitigating foreseeable discrimination risks throughout the AI system's lifecycle. This includes conducting fairness audits and adversarial testing.    

[ ] Establish Post-Market Monitoring: Create a formal process to receive and analyze feedback from deployers and other sources regarding potential discrimination caused by the system after deployment.    

[ ] Develop Incident Response Protocol: Implement a documented, step-by-step plan for notifying the Colorado Attorney General and all known deployers within the 90-day statutory deadline if you discover the system has caused algorithmic discrimination.    

Compliance Documentation Requirements & AI Agent Elicitation Protocol
Document 1: Documentation for Deployers

Required Sections & Information:

General Statement: A description of the reasonably foreseeable uses and known harmful or inappropriate uses of the system.    

System Purpose and Outputs: The systemâ€™s specific purpose, its intended benefits and uses, and a description of its intended outputs.    

Training Data Summary: High-level summaries of the types of data used to train the system.    

Known Limitations: A description of the system's known or reasonably foreseeable limitations, including the risks of algorithmic discrimination.    

Evaluation and Mitigation: A description of how the system was evaluated for performance and fairness, and the methods used to mitigate identified discrimination risks.    

Data Governance: A description of the data governance measures used, covering the training datasets and the suitability of data sources, including how potential biases were examined and mitigated.    

Guidance for Deployers: Instructions on how the system should be used, not be used, and be monitored by an individual to prevent discrimination.    

Impact Assessment Support: Any additional documentation reasonably necessary to assist a deployer in completing their own Impact Assessment, such as model cards or dataset cards.    

Document 2: Public Website Statement

Required Sections & Information:

System Summary: A summary of the types of high-risk AI systems you have developed and currently make available.    

Risk Management Summary: A description of how your company manages the known or reasonably foreseeable risks of algorithmic discrimination.    

AI Agent Elicitation Questions:

For Deployer Documentation:

"Provide a statement describing the intended and reasonably foreseeable uses of the AI system. Also, list any known uses that would be harmful or inappropriate."

"What is the specific purpose of the system, what are its intended benefits, and what are its intended outputs (e.g., a risk score, a classification)?"

"Provide a high-level summary of the types and sources of data used to train the model."

"Describe the system's known limitations. In what scenarios might its performance degrade, become unreliable, or pose a risk of algorithmic discrimination?"

"Describe the technical methods and fairness metrics used to evaluate the system for algorithmic discrimination. What were the results of this evaluation?"

"What specific steps (technical or procedural) were taken to mitigate any discrimination risks that were identified during testing?"

"Describe your data governance measures. How did you assess the suitability of data sources and mitigate potential biases within them?"

"Provide clear guidance for deployers on how the system should be used, how it should not be used, and how it should be monitored by a human to ensure fair outcomes."

For Public Website Statement: 9. "Provide a list of the general categories of high-risk AI systems your company develops (e.g., 'employment screening systems,' 'credit assessment models')." 10. "Provide the summary text for your public website, describing your company's overarching approach to managing the risks of algorithmic discrimination."

4. Deployer of High-Risk AI System
Internal Compliance Actions
[ ] Establish Risk Management Program: Develop, implement, and maintain a formal Risk Management Policy and Program, specifying principles, processes, and personnel. This program should be aligned with a recognized framework like the NIST AI RMF.    

[ ] Conduct Annual System Review: Beyond the formal impact assessment, conduct and document an annual review of each deployed high-risk system to ensure it is not causing algorithmic discrimination.    

[ ] Implement Consumer Rights Processes: Operationally implement the consumer rights you will offer, including the process for data correction and the human review workflow for appeals.    

[ ] Develop Incident Response Protocol: Create a documented, step-by-step plan for notifying the Colorado Attorney General within 90 days of discovering that the deployed system has caused algorithmic discrimination.    

Compliance Documentation Requirements & AI Agent Elicitation Protocol
Document 1: Risk Management Policy and Program

Required Information:

A formal policy specifying the principles, processes, and personnel that your organization uses to identify, document, and mitigate known or reasonably foreseeable risks of algorithmic discrimination.    

Document 2: Impact Assessment

Required Sections & Information:

Purpose and Context: A statement disclosing the purpose, intended use cases, deployment context, and benefits of the system.    

Risk Analysis and Mitigation: An analysis of whether the system poses any known or foreseeable risks of algorithmic discrimination, the nature of such risks, and the steps taken to mitigate them.    

Data Processing: A description of the categories of data the system processes as inputs and the outputs it produces.    

Customization Data (if applicable): An overview of the data categories used to customize the system.    

Performance and Limitations: The metrics used to evaluate the system's performance and its known limitations.    

Transparency Measures: A description of transparency measures taken, including how consumers are notified of the system's use.    

Monitoring and Safeguards: A description of post-deployment monitoring and user safeguards, including oversight and learning processes.    

Document 3: Public Website Statement

Required Sections & Information:

Deployed Systems Summary: A summary of the types of high-risk AI systems you currently deploy.    

Risk Management Summary: A description of how you manage the known or reasonably foreseeable risks of algorithmic discrimination from these systems.    

Data Collection Summary: The nature, source, and extent of information collected and used by the AI systems.    

Document 4: Consumer Pre-Decision Notice

Required Information:

A statement that a high-risk AI system is being used to make, or is a substantial factor in making, a consequential decision.    

The purpose of the AI system and the nature of the consequential decision.    

The deployer's contact information.    

Instructions on how to access the public website statement.    

Document 5: Adverse Action Notice

Required Information:

The principal reason(s) for the adverse decision.    

The degree to which and manner in which the AI system contributed to the decision.    

The type and source of data processed by the system to make the decision.    

Instructions on how the consumer can correct incorrect personal data.    

Instructions on how the consumer can appeal the decision for human review.    

AI Agent Elicitation Questions:

For Risk Management Program & Public Statement:

"Who is the designated executive accountable for your AI risk management program? Provide their name and title."

"Describe your organization's core principles for the responsible deployment of AI."

"Provide the summary text for your public website, describing the types of high-risk systems you deploy and your approach to managing their risks."

"For your public statement, describe the nature, source, and extent of the data your high-risk systems collect and use."

For Impact Assessment: 5. "State the specific purpose, intended use cases, and expected benefits of the AI system." 6. "What are the specific, foreseeable risks of algorithmic discrimination you have identified for your customers, and what mitigation steps have you taken for each?" 7. "List the categories of data the system uses as inputs and produces as outputs." 8. "What metrics do you use to evaluate the system's performance, and what are its known limitations?" 9. "Describe your plan for post-deployment monitoring and the safeguards in place for users."

For Consumer Notices: 10. "Provide the exact text for the notice that will be shown to consumers before a consequential decision is made." 11. "For an adverse decision, what is the process for generating and providing a consumer with the principal reason(s)?" 12. "Provide the exact text explaining the consumer's right to appeal an adverse decision, including the step-by-step instructions they must follow."

5. Both Developer and Deployer of High-Risk AI System
Internal Compliance Actions
[ ] Establish Unified Governance: Create a single, integrated Risk Management Policy and Program that governs the entire AI lifecycle, from initial design and data collection through deployment and ongoing monitoring.

[ ] Integrate Workflows: Establish clear internal processes that ensure your 'Deployer' teams have full access to and understanding of the technical details, limitations, and risk assessments produced by your 'Developer' teams.

[ ] Conduct Comprehensive Testing: Perform and document rigorous technical analysis, performance evaluation, and bias testing required of a developer, and use this as a primary input for the Impact Assessments required of a deployer.

[ ] Implement Unified Incident Response: Create a single, streamlined protocol for notifying the Attorney General within 90 days of discovering that the system has caused algorithmic discrimination.

Compliance Documentation Requirements & AI Agent Elicitation Protocol
As a dual-role entity, you must comply with the documentation requirements of both a Developer and a Deployer. While you are not required to generate the formal "Documentation for Deployers" for your own internal use, you must have all of that information readily available to complete your Deployer obligations, such as the Impact Assessment.    

All documents listed under the Developer (3) and Deployer (4) classifications are required. This includes:

Internal Analysis (Equivalent to Developer Documentation for Deployers)

Risk Management Policy and Program

Impact Assessment

Consolidated Public Website Statement (covering both development and deployment)

Consumer Pre-Decision Notice

Adverse Action Notice

AI Agent Elicitation Questions:

For Integrated Governance:

"Describe the process that ensures your deployment teams have full access to the technical limitations and risk assessments produced by your development teams. This will inform the governance section of your documentation."

"How does your organization manage and resolve potential internal conflicts between development goals (e.g., model accuracy) and deployment responsibilities (e.g., fairness, consumer rights)?"

For All Other Documents: 3. Please answer all questions listed in the AI Agent Elicitation Protocol for the Developer of a High-Risk AI System (Section 3). 4. Please answer all questions listed in the AI Agent Elicitation Protocol for the Deployer of a High-Risk AI System (Section 4).