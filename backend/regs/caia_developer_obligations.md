# Colorado AI Act § 6-1-1702 — Developer Obligations

## Duty of Care (§ 6-1-1702(1))

A developer shall use reasonable care to protect consumers from any known or reasonably foreseeable risks of algorithmic discrimination arising from the intended and contracted uses of any high-risk artificial intelligence system that the developer develops.

A developer maintains a rebuttable presumption that the developer has used reasonable care to protect consumers if the developer complies with the requirements specified in this section.

## Documentation and Disclosure (§ 6-1-1702(2))

A developer of a high-risk artificial intelligence system shall make documentation and a statement available to any deployer before or contemporaneously with the deployer's use of the high-risk AI system. The documentation must include:

1. A general statement describing the reasonably foreseeable uses and known harmful or inappropriate uses of the high-risk AI system
2. A summary of the type of data used to train the high-risk AI system
3. A description of how the high-risk AI system was evaluated for performance and mitigation of algorithmic discrimination, limitations of the evaluation, and metrics the deployer may use to evaluate performance
4. A description of the data that the deployer must provide to the developer to monitor the high-risk AI system
5. An overview of the type of data that the deployer should use with the high-risk AI system
6. Any known or reasonably foreseeable limitations of the high-risk AI system, including known or reasonably foreseeable risks of algorithmic discrimination

## Updates and Modifications (§ 6-1-1702(3))

When a developer becomes aware that a deployed high-risk AI system has produced algorithmic discrimination or otherwise poses an unreasonable risk to consumers, the developer shall:
1. Provide notice to deployers within 90 days of discovery
2. Provide documentation of the nature of the algorithmic discrimination or unreasonable risk

## Testing and Validation (§ 6-1-1702(4))

A developer shall implement appropriate procedures and processes to test a high-risk AI system to identify known or reasonably foreseeable risks of algorithmic discrimination, which may include testing:
- Before the high-risk AI system is deployed for use
- Using representative, reasonably up-to-date data sets

## Trade Secret Protection (§ 6-1-1702(6))

The requirements of this section do not require a developer to disclose a trade secret or information protected from disclosure by state or federal law or to disclose information that would create a security risk.

