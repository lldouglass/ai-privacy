# Outcome 9: Both Developer and Deployer of High-Risk AI System

## Overview

This outcome applies to entities that are **both** a developer and a deployer of the same high-risk AI system. This means you:

1. **Develop or intentionally and substantially modify** a high-risk AI system, AND
2. **Deploy that same system** in your own business operations in Colorado

When you are both the developer and deployer, you are subject to **all obligations** under both § 6-1-1702 (developer obligations) and § 6-1-1703 (deployer obligations).

## Effective Date

**February 1, 2026** — Both developer and deployer obligations under the Colorado AI Act take effect on this date.

## Common Scenarios

You may be both a developer and deployer if you:

- Build custom AI systems in-house and use them to make consequential decisions
- Substantially modify a third-party AI system and then deploy the modified version
- Develop AI systems as a vendor and also use them internally for consequential decisions
- Create AI-powered products/services and use them in your own operations

## Combined Duty of Care

### Developer Duty (§ 6-1-1702(1))
Use reasonable care to protect consumers from known or reasonably foreseeable risks of algorithmic discrimination arising from the **intended and contracted uses** of the high-risk AI system you develop.

### Deployer Duty (§ 6-1-1703(1))
Use reasonable care to protect consumers from known or reasonably foreseeable risks of algorithmic discrimination arising from your **deployment and use** of the high-risk AI system.

### Rebuttable Presumption
If you comply with all requirements in **both** § 6-1-1702 and § 6-1-1703, you maintain a rebuttable presumption of reasonable care for both roles.

## All Developer Obligations (§ 6-1-1702)

Even though you are deploying the system yourself, you must still comply with developer obligations:

### 1. Documentation (§ 6-1-1702(2))

Create comprehensive documentation covering:
- General statement of reasonably foreseeable uses and known harmful uses
- Summary of training data types
- Performance evaluation description and limitations
- Monitoring data requirements
- Data input overview
- Known limitations and risks of algorithmic discrimination

**Note**: While you may not need to provide this documentation to yourself as the deployer, maintaining this documentation:
- Helps you comply with your deployer obligations
- Provides evidence of reasonable care
- Is required if you later provide the system to other deployers

### 2. Testing and Validation (§ 6-1-1702(4))

Implement appropriate procedures to test the high-risk AI system before deployment:
- Conduct pre-deployment testing
- Use representative, reasonably up-to-date data sets
- Identify risks of algorithmic discrimination

### 3. Ongoing Monitoring and Notification (§ 6-1-1702(3))

Monitor the deployed system for algorithmic discrimination or unreasonable risks:
- If you discover issues, document them
- If you provide the system to other deployers in the future, notify them within 90 days

### 4. Trade Secret Protection Rights (§ 6-1-1702(6))

You maintain the right to protect trade secrets and security-sensitive information, even in your own documentation.

## All Deployer Obligations (§ 6-1-1703)

As a deployer of your own high-risk AI system, you must comply with all deployer obligations:

### 1. Risk Management Policy and Program (§ 6-1-1703(2))

Implement a documented risk management policy and program including:
- Policies, procedures, and practices to manage algorithmic discrimination risks
- Regular identification, documentation, and mitigation of risks
- Annual review and updates

### 2. Impact Assessment (§ 6-1-1703(3))

Complete an impact assessment **before deployment** containing:
- Purpose, intended use cases, benefits, and deployment context
- Analysis of discrimination risks
- Description of data categories and data management practices
- Description of risk management implementation
- Performance metrics for evaluating algorithmic discrimination

**Disclosure requirements:**
- Make available to the Attorney General upon request
- (Self-provision to developer role not separately required since you are both)

### 3. Public Summary (§ 6-1-1703(4))

Publish a public summary on your website including:
- Intended use of the high-risk AI system
- How you manage risks of algorithmic discrimination

### 4. Consumer Notices (§ 6-1-1703(5))

When making or substantially influencing consequential decisions, provide consumers:
- Statement that a high-risk AI system was used
- Information about the system's purpose
- Nature of the consequential decision
- Contact information
- Rights to opt out (if applicable)
- Rights to appeal and seek human review

### 5. Adverse Decision Requirements (§ 6-1-1703(6))

For adverse consequential decisions, provide:
- Explanation of principal reasons
- Opportunity to correct incorrect personal data
- Appeal process with human review (where technically feasible)

### 6. Attorney General Notification (§ 6-1-1703(7))

If you discover algorithmic discrimination:
- Notify the Attorney General as soon as reasonably practicable
- Provide information about the nature and extent of the discrimination

### 7. Trade Secret Protection (§ 6-1-1703(8))

You may withhold trade secrets and security-sensitive information from consumer disclosures, but must:
- Notify consumers that information is being withheld
- State the basis for withholding

## Integration Benefits

Being both the developer and deployer can provide advantages:

### Unified Risk Management
- Your developer testing informs your deployer risk management
- Your deployment experience informs your development improvements
- Single, integrated compliance program covering both roles

### Better Documentation
- Developer documentation serves as foundation for impact assessments
- Testing results directly support risk management policies
- Continuous feedback loop for improvement

### Streamlined Compliance
- One team can coordinate both developer and deployer requirements
- Shared documentation reduces duplication
- Unified approach to reasonable care

## Practical Compliance Steps

### Before Deployment (Developer Role):
1. Conduct comprehensive testing with representative data
2. Create full developer documentation (even for internal use)
3. Identify and document all known risks and limitations

### Before Deployment (Deployer Role):
4. Create risk management policy and program
5. Complete impact assessment
6. Publish public summary on website
7. Establish consumer notice and appeal procedures

### During Operations (Combined):
8. Monitor for algorithmic discrimination
9. Maintain and update risk management annually
10. Provide consumer notices for all consequential decisions
11. Process appeals with human review
12. Update documentation and impact assessments as needed

### If Issues Arise (Combined):
13. Document discovered discrimination or risks
14. Notify Attorney General (deployer obligation)
15. Notify any other deployers if applicable (developer obligation)
16. Take corrective action
17. Update all relevant documentation

## Exemptions

Even if you are both developer and deployer, you may qualify for deployer exemptions:

- **Small deployer exemptions**: If you meet size thresholds, your deployer obligations may be reduced or eliminated (see Outcome 2)
- **Industry exemptions**: Insurance, banking, and other regulated industries may have modified obligations (see Outcome 2)
- **Developer obligations remain**: Even if exempt as a deployer, you likely still have developer obligations if you provide the system to others

## Enforcement and Penalties

**§ 6-1-1706 — Enforcement**

Violations of either developer or deployer obligations constitute **deceptive trade practices** under the Colorado Consumer Protection Act.

You can be held accountable for:
- Developer obligation violations (§ 6-1-1702)
- Deployer obligation violations (§ 6-1-1703)
- Both simultaneously

## Compliance Frameworks

**Safe Harbor Option**

Comply with a nationally or internationally recognized risk management framework to establish safe harbor compliance for both roles:
- NIST AI Risk Management Framework
- ISO/IEC AI standards
- Other frameworks recognized by the Attorney General

Benefits:
- Single framework can address both developer and deployer obligations
- Provides strong evidence of reasonable care
- May simplify compliance demonstration

## Comparison to Other Outcomes

| Aspect | Outcome 7 (Developer Only) | Outcome 8 (Deployer Only) | Outcome 9 (Both) |
|--------|---------------------------|---------------------------|------------------|
| Developer obligations | ✓ Yes | ✗ No | ✓ Yes |
| Deployer obligations | ✗ No | ✓ Yes | ✓ Yes |
| Testing required | ✓ Yes | ✗ No | ✓ Yes |
| Impact assessment | ✗ No | ✓ Yes | ✓ Yes |
| Risk management policy | ✗ No | ✓ Yes | ✓ Yes |
| Consumer notices | ✗ No | ✓ Yes | ✓ Yes |
| Public summary | ✗ No | ✓ Yes | ✓ Yes |
| Developer documentation | ✓ Yes | ✗ No | ✓ Yes |

## Related Provisions

- § 6-1-1702 — Complete developer obligations
- § 6-1-1703 — Complete deployer obligations
- § 6-1-1706 — Enforcement provisions
- **Developer** (§ 6-1-1701(4)) — Definition
- **Deployer** (§ 6-1-1701(5)) — Definition
- **High-Risk Artificial Intelligence System** (§ 6-1-1701(9)) — What triggers these obligations
- **Algorithmic Discrimination** (§ 6-1-1701(1)) — The primary risk to manage
- Outcome 2 — Potential deployer exemptions
- Outcome 7 — Developer-only obligations (for comparison)
- Outcome 8 — Deployer-only obligations (for comparison)

